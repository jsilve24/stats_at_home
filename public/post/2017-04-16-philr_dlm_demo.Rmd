---
title: Compositional Time Series Analysis with PhILR and Dynamic Linear Models
author: Justin Silverman
date: '2017-04-16'
slug: philr_dlm_demo
categories:
  - R
tags:
  - Dynamic Linear Models
  - PhILR
  - Compositional Data
  - Time Series Analysis
bibliography: 2017-04-16_philr_dlm_demo_extra/philr.bib
---


We are going to simulate a compositional time-series of a 3 species population 
and we will view the dynamics in terms of the phylogenetic tree using the PhILR 
coordinates system. 
Specifically we are going to model a community that is undergoing a mean-reverting
stochastic process and being acted on by an external force which itself is undergoing a 
random walk. 
On top of this we will simulate observational noise which obscures our measurements 
of the true community state at any given time. 

To analyze this dataset we are going to use a Dynamic Linear Model 
with a simple first-order polynomial trend and an added dynamic regression component. 

First we load a few packages we are going to use.
```{r, message=FALSE, warning=FALSE}
library(philr)
library(compositions)
library(MASS) # For mvrnorm
library(dlm) 
library(tidyverse)
library(ggtree)
library(gridExtra)
set.seed(4)

# These functions are shown at the bottom of this report
source("2017-04-16_philr_dlm_demo_extra/utils.R") 
```


# Overview of PhILR Analysis
The goal of PhILR is to transform compositional data into an unconstrained space with an orthonormal basis with phylogenetic / evolutionary interpretation while preserving all information contained in the original composition. Unlike in the original compositional space, in the transformed real space, standard statistical tools may be applied. For a given set of samples consisting of measurements of  taxa, we transform data into a new space of  samples and  orthonormal coordinates termed ‘balances’. Each balance  is associated with a single internal node of a phylogenetic tree with the taxa as leaves. The balance represents the log-ratio of the geometric mean abundance of the two groups of taxa that descend from the given internal node. More details on this method can be found in @silverman2017 ([Link](https://elifesciences.org/content/6/e21887)). The package `philr` can be 
downloaded from [bioconductor](https://bioconductor.org/packages/release/bioc/html/philr.html). 


# Simulating the Data
First we will simulate a phylogenetic tree connecting these three species. 
Our new transformed coordinates end up being associated with the internal nodes
of the phylogenetic tree (which we prefix with an "n"). We use the function 
`philr::annotate_balance()` which allows us to easily 
annotate which clade is in the numerator (+) and which is in the denominator (-)
of each balance. 
We also rotate one of the internal nodes so that the clades in the numerator
correspond to the clade that is towards the bottom of the tree in this layout. 
```{r, message=FALSE, warning=FALSE}
tr <- read.tree(text="((t2:0.268,t1:0.958)n2:0.734,t3:0.257)n1;")

# Now we visualize the tree and the Blances
p <- ggtree(tr) +
  geom_label(aes(label=label))
p <- rotate(p, 4) %>% 
  rotate(5)
p <- annotate_balance(tr, "n2", labels=c("n2+","n2-"), p, offset=.2, barsize = .05, offset.text = .1)
p <- annotate_balance(tr, "n1",labels=c("n1+","n1-"), p, offset = .5, barsize=0.05, offset.text = .1)
p
```


Next we are going to come up with a hypothetical intervention/exogenous
time-series increases species t3 relative to species t1 and t2. 
For example, this could be a dietary food-source in the environment that
we are interested in exploring. 
```{r}
t <- 150 # length of time-series
x <- cumsum(sample(c(-.5, .5), t, TRUE)) # simulate an arbitrary random walk
x <- x + abs(min(x)) # make sure all the values are positive for this example
plot(ts(x))
```



Next we are going to simulate our time-series using the compositional 
operations of perturbation and powering. We simulate a community
with three simulataneous processes. First we simulate that the community
is undergoing a mean-reverting stochastic process. 

$$
\begin{aligned}
\mu_t &= \phi\otimes \mu_{t-1} \oplus w_t \\
w_t & \sim LN(0,\Sigma_{\text{state}})
\end{aligned}
$$

Where $\mu_t$ denotes the state of the community attributable to this mean-reverting process
at time $t$, $LN$ denotes the Logsitic Normal distribution and $\Sigma_{\text{state}}$ denotes
the covariance of this state noise. 
In addition we simulate that exogenous variable $x$ influences the immediate state of the 
system in a compositionally additive way and that the influence is given by the 
compositional vector $\beta$ which encodes how the exogenous variable influences
the relative abundances of each taxa 

$$\theta_t = \mu_t \oplus \beta \otimes x_t.$$
Here we call $\theta_t$ the true state of the system at time $t$. Specifically
we are goint to simulate that $x$ increases t3 over t1 and t2. 
We also simulate that we do not measure this true state of the system but only obtain
noisy measurements of this true state given by 

$$
\begin{aligned}
y_t &= \theta_t \oplus v_t \\
v_t & \sim LN(0,\Sigma_{\text{obs}}). 
\end{aligned}
$$


```{r}
y <- matrix(0, nrow=t, ncol=3)
y[1,] <- clo(c(1,1,1)) # Equally abundant starting point
phi <- .9  # Autoregressive coefficient 
beta <- acomp(c(1,1,2))
names(beta) <- tr$tip.label

# Parameters for the noise
m <- c(0,0)
Sigma.State <- matrix(c(1,0,0,1), nrow=2)
Sigma.Noise <- matrix(c(1,0,0,1), nrow=2)

# Autoregressive Structure
for (i in 2:t){
  y[i,] <- acomp(y[i-1,])*phi + acomp(rlogisticnormal(1, m, Sigma.State, tr))
}

# Added Exogenous Regression Component and Added Logistic Normal Noise
for (i in 1:t){
  y[i,] <-  acomp(y[i,]) + beta*x[i] +  acomp(rlogisticnormal(1, m, Sigma.Noise, tr))
}

colnames(y) <- tr$tip.label
```

Now we will look at the simulated data in terms of relative abundances

```{r}
plot(ts(y))
```

Now we will visualize the data in the PhILR basis
```{r, message=FALSE}
y.ilr <- philr(y, tr)
plot(ts(y.ilr))
```


# Modeling the Simulated Data
We are going to model the data using the following state-space model that makes
use of the PhILR transform

$$
\begin{aligned}
y_t & = \text{PhILR}^{-1}(\eta_t) &\\
\eta_t &= \mu_t + \beta x_t+v_t & v_t \sim N(0, \Sigma_\text{obs}) \\
\mu_t & = \mu_{t-1} + w_t & w_t \sim N(0, \Sigma_\text{state})
\end{aligned}
$$
where $\text{PhILR}^{-1}$ denotes the inverse PhILR transform. 
Note that here we have made use of the very convenient properties of the ILR transform, 
where perturbation and powering are transformed to addition and multiplication and 
the logistic normal distribution is transformed to the multivariate normal distribution. 

For this example, we are going to assume that we know $\Sigma_\text{obs}$ but need to 
estimate $\Sigma_\text{state}$. We will estimate $\Sigma_\text{state}$ by using 
the Maximum Likelihood estimate. 

```{r}
# Write a function to build our model based on parameter values
build <- function(param){
  
  mod <- dlmModPoly(order=1, dV = 1, dW = param[1]) + dlmModReg(x, addInt=F, dV = 1e-7, dW = 1e-7)

  # Now expand to Multivariate
  mod$FF <- mod$FF %x% diag(2)
  mod$JFF <- mod$JFF %x% diag(2)
  mod$GG <- mod$GG %x% diag(2)
  mod$V <- mod$V %x% diag(2) # Here we assume no observation noise
  mod$W <-mod$W %x% diag(2)
  mod$m0 <- c(mod$m0, mod$m0)
  mod$C0 <- mod$C0 %x% diag(2)
  return(mod)
}

# Now Find MLE for State Covariance
fit <- dlmMLE(y.ilr, rep(1,1), build, lower=c(1e-6))

# Build the model with the fitted parameter
mod <- build(fit$par)

# Run Forward Filtering Backwards Sampling Algorithm to Obtain Samples from Posterior of states
filt <- dlmFilter(y.ilr, mod) # Forward Filtering

sm.samples <- array(0, dim=c(151, 4, 300))
for (i in 1:300){
  sm.samples[,,i] <- dlmBSample(filt) # Backwards Sampling
}
```


Now we are going to investigate these posterior estimates. 
First we are going to look at the posterior estimates for $\theta_t$ (recall we
defined $\theta_t=mu_t+\beta x$. 
```{r, fig.height=5, fig.width=10, message=TRUE}
sm.mean.sample <- array(0, dim=c(150, 2, 300))
for (i in 1:300){
  sm.mean.sample[,,i] <- ftheta(mod, sm.samples[,,i])
}

tidy_y_ilr <- tidy_array(y.ilr) %>% 
  rename(mean=var) %>% 
  mutate(dim_2 = factor(dim_2, labels=c("n1", "n2")))

p.smooth <- tidy_array(sm.mean.sample) %>% 
  group_by(dim_1, dim_2) %>% 
  summarize(mean=mean(var), 
            p25 = quantile(var, prob=0.25), 
            p75 = quantile(var, prob=0.75)) %>% 
  mutate(dim_2 = factor(dim_2, labels=c("n1", "n2"))) %>% 
  ggplot(aes(x=dim_1, y=mean)) +
  geom_line(data=tidy_y_ilr, color="red") +
  geom_point(data=tidy_y_ilr, color="red") +
  geom_ribbon(aes(ymin=p25, ymax=p75), fill="darkgrey", alpha=0.5) +
  geom_line() +
  facet_grid(dim_2~.) +
  theme_bw() +
  ggtitle("Posterior Smoothing Estimates and 50% Probability Limits for System State") +
  xlab("Time") +
  ylab("Balance Value")

grid.arrange(p, p.smooth, ncol=2, widths=c(3,5))  
```

We have plotted the PhILR transformed time-series in Red and our mean smoothing estimates
in black. The grey ribbon represents the 95% probability limits for our 
posterior estimate of the state. 
We can see that there appears to be a fair bit of dynamics occuring in all the species
and we don't see any particular phylogenetic signal from $\theta_t$. So next
we are going to decompose this time-series and look at each of the 
processes we modeled sepearately. That is we are going to look at $\mu_t$ and 
$\beta x_t$ separately. 

```{r, fig.height=5, fig.width=10}
p.decomp <- sm.samples %>% 
  .[2:151,,] %>% # Same thing as dropFirst but for 3D array
  tidy_array() %>% 
  group_by(dim_1, dim_2) %>% 
  mutate(var = ifelse(dim_2 %in% c(3,4), var*x[dim_1], var)) %>% 
  summarize(mean=mean(var), 
            p25 = quantile(var, prob=0.25), 
            p75 = quantile(var, prob=0.75)) %>% 
  mutate(coord = ifelse(dim_2 %in% c(1,3), 1,2), 
         Parameter = ifelse(dim_2 %in% c(1,2), "Mu", "BetaX")) %>% 
  mutate(coord = factor(coord, labels=c("n1", "n2"))) %>% 
  ggplot(aes(x=dim_1, y=mean, group=Parameter)) +
  geom_ribbon(aes(ymin=p25, ymax=p75), fill="darkgrey", alpha=0.5) +
  geom_line(aes(color=Parameter)) +
  facet_grid(coord~.) +
  theme_bw() +
  ggtitle("Decomposition of Smoothing Estimates with 50% Probability Limits") +
  xlab("Time") +
  ylab("Balance Value")

grid.arrange(p, p.decomp, ncol=2, widths=c(3,5))  
```

The first thing to notice is that our posterior estimates for these
two processes are quite large compared to our posterior estimates for 
$\theta_t$. This indicates that while the model is fairly certain
about the sum of these two processes, it is less certain about the relative
contributions of each. 
Yet despite this uncertainty we still a assymetry in the $\beta x_t$ 
series. It looks as though the model is fairly certain that the external covariate
$x_t$ is decreasing t1 relative to t2 (negative in n1) and the model 
believes that it is most likely that $x_t$ is not having much effect on the t3 to (t1,t2) 
ratio (n2). 

Now we are going to look at the estimates for $\beta$ and compare these
to the true values. Since we assumed that $w_\beta$ was relatively constant
we only need to look at $\beta$ for a single time-point. We will 
just take time-point 74. 
```{r, fig.height=4, fig.width=8, message=FALSE}
beta_ilr <- philr(unclass(beta), tr)
tidy_beta_ilr <- data.frame(dim_2=factor(c("n1","n2"), levels=c("n2", "n1")), mean=c(beta_ilr[,1], beta_ilr[,2]))

p.bal <- sm.samples %>% 
  tidy_array() %>% 
  filter(dim_1 == 75,   # Recall first time-point is t=0
         dim_2 %in% c(3,4)) %>% 
  group_by(dim_2) %>% 
  summarize(mean=mean(var), 
            p2.5 = quantile(var, prob=0.025), 
            p97.5 = quantile(var, prob=0.975)) %>% 
  mutate(dim_2= factor(dim_2, labels=c("n1","n2"))) %>%
  mutate(dim_2 = relevel(dim_2, c("n2"))) %>% 
  ggplot(aes(x=dim_2, y=mean)) +
  geom_errorbar(aes(ymin=p2.5, ymax=p97.5))+
  geom_point() +
  geom_point(data=tidy_beta_ilr, color="red")+
  theme_bw()+
  ggtitle("Smoothing Estimate for Beta with 95% probability Limit") +
  ylab("Balance Value") +
  xlab("Balance") +
  coord_flip()

grid.arrange(p, p.bal, ncol=2, widths=c(2,1))  
```

We have plotted the true value for beta in red. First, note that our mean posterior estiamte
is quite close to the true value of $\beta$. That is, our model has done quite well
learning how the $x_t$ series influences the community we are studying. Secondly
we see that the effect of $x_t$ is primarily on the ratio of t1 to t2 and 
is not involving t3 vs (t1, t2). 

Finally, if desired we can view the effects of $x_t$ in terms of relative abundances 
by simply taking the inverse PhILR transpose of $\beta$ 

```{r}
sm.samples %>% 
  .[75,3:4,] %>% 
  t %>% 
  `colnames<-`(c('n1','n2')) %>% # Need to set column names
  philrInv(tr) %>% 
  as.data.frame() %>% 
  select(t1, t2, t3) %>% 
  summary()
```

Now we will compare to the true value 
```{r}
(philrInv(beta_ilr, tr)) # The true value
```

While there is some uncertainty, we see that our estimates are close to the true values. 


# Helper Functions
```{r}
writeLines(readLines("2017-04-16_philr_dlm_demo_extra/utils.R"))
```


# Original Computing Environment
```{r}
devtools::session_info()
```

